{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "496631ea",
      "metadata": {
        "id": "496631ea"
      },
      "source": [
        "# Módulo 1: Análisis de datos en el ecosistema Python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a14cd3f",
      "metadata": {
        "id": "3a14cd3f"
      },
      "source": [
        "### Sesión (18)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbaae337",
      "metadata": {
        "id": "fbaae337"
      },
      "source": [
        "## Aplicar un caso de uso (*Clasificación*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d4a1419",
      "metadata": {
        "id": "1d4a1419"
      },
      "outputs": [],
      "source": [
        "# importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d67e37",
      "metadata": {
        "id": "14d67e37"
      },
      "outputs": [],
      "source": [
        "# Modificamos los parámetros de los gráficos en matplotlib\n",
        "from matplotlib.pyplot import rcParams\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 6 # el primer dígito es el ancho y el segundo el alto\n",
        "rcParams[\"font.weight\"] = \"bold\"\n",
        "rcParams[\"font.size\"] = 10\n",
        "rcParams[\"axes.labelweight\"] = \"bold\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2a7c738",
      "metadata": {
        "id": "a2a7c738"
      },
      "source": [
        "### Dataset de cubierta forestal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa35de9",
      "metadata": {
        "id": "5fa35de9"
      },
      "source": [
        "**[Forest Covertype data](https://archive.ics.uci.edu/ml/datasets/Covertype)** es un conjunto de datos cargado en la librería _sklearn_ que permite realizar un ejercicio tipo problemas de **clasificación**. El objetivo de este dataset es **estudiar las variables cartográficas** para poder **predecir el tipo de cubierta forestal**. El tipo real de cubierta forestal para una observación (celda de 30 x 30 metros) se ha determinado a partir de los datos del **Servicio Forestal de EE.UU. (USFS)**.\n",
        "\n",
        "Los datos están en forma **cruda** (sin escalar) y contienen columnas binarias (0 o 1) de datos para variables independientes cualitativas (áreas silvestres y tipos de suelo).\n",
        "\n",
        "Estas áreas de estudio representan **bosques con mínimas perturbaciones causadas por el hombre**, por lo que los tipos de cubierta forestal existentes son más el **resultado de procesos ecológicos**, que de prácticas de gestión forestal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df9cf699",
      "metadata": {
        "id": "df9cf699"
      },
      "source": [
        "### Análisis Exploratorio Inicial, Tratamiento y Limpieza de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe776ee0",
      "metadata": {
        "id": "fe776ee0"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "\n",
        "# Construimos un dataframe con los datos medidos de la cubierta forestal\n",
        "dataset_cub = pd.DataFrame(fetch_covtype()[\"data\"], columns=fetch_covtype()[\"feature_names\"])\n",
        "\n",
        "# Añadimos la variable objetivo\n",
        "dataset_cub['target'] = fetch_covtype()[\"target\"]\n",
        "\n",
        "dataset_cub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c865ed5a",
      "metadata": {
        "id": "c865ed5a"
      },
      "source": [
        "Vamos a sacar un dataset mucho más pequeño para **simplificar los cálculos** y **reducir el tiempo de computación** de los algoritmos. Una primera idea para extraer un subconjunto podría ser quedarnos por ejemplo con los **_100.000_ primeros registros** de la tabla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10d4737",
      "metadata": {
        "id": "f10d4737"
      },
      "outputs": [],
      "source": [
        "dataset_cub[0:100000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a74f10",
      "metadata": {
        "id": "b2a74f10"
      },
      "source": [
        "El posible peligro de este enfoque es que **no obtengamos un subconjunto muy representativo**. Realizamos una consulta sobre una de las variables del datset para ver si estadísticamente tienen las mismas características o no."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88cbe207",
      "metadata": {
        "id": "88cbe207"
      },
      "outputs": [],
      "source": [
        "dataset_cub['Elevation'].describe()[['count', 'mean', 'std']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e9653c0",
      "metadata": {
        "id": "9e9653c0"
      },
      "outputs": [],
      "source": [
        "dataset_cub[0:100000]['Elevation'].describe()[['count', 'mean', 'std']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c46d7f",
      "metadata": {
        "id": "08c46d7f"
      },
      "outputs": [],
      "source": [
        "# Comparar la distribución de la variable \"Elevation\" entre los dos Dataframes\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18,9))\n",
        "sns.histplot(dataset_cub['Elevation'], bins=200, ax=axes[0])\n",
        "sns.histplot(dataset_cub[0:100000]['Elevation'], bins=200, ax=axes[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226fd6f9",
      "metadata": {
        "id": "226fd6f9"
      },
      "source": [
        "Se puede observar que la variable analizada no tiene la misma representación en el subconjunto de los _100.000_ primeros registros del dataset. Otra opción para conseguir un trozo de los datos originales, sería aplicar la técnica de **remuestro aleatorio (_random resampling_)**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "430bf8ed",
      "metadata": {
        "id": "430bf8ed"
      },
      "source": [
        "Vamos a hacer un remuestreo aleatorio para **quedarnos aproximadamente con el 17% de los datos** usando el método **[sample](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)** sobre los _DataFrames_ de la librería _pandas_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880befd7",
      "metadata": {
        "id": "880befd7"
      },
      "outputs": [],
      "source": [
        "100/6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZHVM7fdPLr4"
      },
      "outputs": [],
      "source": [
        "df_cub = dataset_cub.sample(frac=1/5.81012, random_state=222).reset_index(drop=True)\n",
        "df_cub"
      ],
      "id": "RZHVM7fdPLr4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ccd3683",
      "metadata": {
        "id": "3ccd3683"
      },
      "outputs": [],
      "source": [
        "# Consultamos las principales esdadísticas de la variable analizada anteriormente\n",
        "df_cub['Elevation'].describe()[['count', 'mean', 'std']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e5cb55",
      "metadata": {
        "id": "08e5cb55"
      },
      "outputs": [],
      "source": [
        "# Comparar la distribución de la variable \"Elevation\" entre el DataFrame original y el subconjunto obtenido mediante el remuestreo aleatorio\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18,9))\n",
        "sns.histplot(dataset_cub['Elevation'], bins=200, ax=axes[0])\n",
        "sns.histplot(df_cub['Elevation'], bins=200, ax=axes[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde8dcaf",
      "metadata": {
        "id": "dde8dcaf"
      },
      "source": [
        "Podemos ver que este último subconjunto, a pesar de tener solamente 17% de los datos, **sí que incluye un set de observaciones muy representativas** respecto al dataset original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17c1eb9",
      "metadata": {
        "id": "f17c1eb9"
      },
      "outputs": [],
      "source": [
        "# Comparar la distribución de la variable objetivo entre los dos Dataframes\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18,5))\n",
        "sns.histplot(dataset_cub['target'], bins=20, ax=axes[0])\n",
        "sns.histplot(df_cub['target'], bins=20, ax=axes[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8386f4d6",
      "metadata": {
        "id": "8386f4d6"
      },
      "outputs": [],
      "source": [
        "df_cub.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc6f1af",
      "metadata": {
        "id": "2dc6f1af"
      },
      "outputs": [],
      "source": [
        "df_cub.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57bd2075",
      "metadata": {
        "id": "57bd2075"
      },
      "outputs": [],
      "source": [
        "# Conteo de valores perdidos/faltantes\n",
        "df_cub.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147dc31c",
      "metadata": {
        "id": "147dc31c"
      },
      "outputs": [],
      "source": [
        "# Consultamos los registros que tienen algún valor nulo\n",
        "df_cub.drop(df_cub.dropna().index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a0bf0cc",
      "metadata": {
        "id": "9a0bf0cc"
      },
      "source": [
        "### Reducción de Variables (___Dimensionality Reduction___)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad08a016",
      "metadata": {
        "id": "ad08a016"
      },
      "source": [
        "### **`Ejercicio 18.1`**\n",
        "\n",
        "Para conseguir un dataset con una dimensión reducidad, aplica la técnica de **Selección de variables basada en árbol de decisión** mediante las importancias de cada variable (**`Decision Trees Importances`**):\n",
        "\n",
        "- Filtra el tablón para quedarnos solamente con **las variables que aglutinan hasta el `95%` de la información** que se requiere para estimar la variable objetivo.\n",
        "- `random_state=100`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25620659",
      "metadata": {
        "id": "25620659"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ece0b60",
      "metadata": {
        "id": "4ece0b60"
      },
      "source": [
        "### **`Ejercicio 18.2`**\n",
        "\n",
        "Después de filtrar el dataset vamos a plantear un **problema de clasificación** para conseguir un **clasificador de la cubierta forestal** en basea a las **variables cartográficas**.:  \n",
        "\n",
        "**`18.2.1`** Genera una gráfica para visualizar la distribución de las variables del datset en conjunto. Analiza dicha gráfica y explica si hay una necesidad de normalizar los datos.  \n",
        "\n",
        "**`18.2.2`** Normaliza todas las variables del dataset a una escala estándar. Para ello puedes realizar estas transformaciones:\n",
        "\n",
        "- LLevar las variables de entrada a una escala de `0` a `1`\n",
        "- Convertir la variable objetivo en valores numéricos **entre 0 y el número de clases menos 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e22253",
      "metadata": {
        "id": "21e22253"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3764f772",
      "metadata": {
        "id": "3764f772"
      },
      "source": [
        "### **`Ejercicio 18.3`**\n",
        "\n",
        "Después de estandarizar los datos procedemos a crear el **primer clasificador**:  \n",
        "\n",
        "**`18.3.1`** Divide el datset en _training_ y en _test_:\n",
        "- Guarda el `20%` de los datos para testeo.\n",
        "- `random_state=100`  \n",
        "\n",
        "**`18.3.2`** Entrena un modelo de **regresión logística**:\n",
        "- Número máximo de iteraciones igual a `1000`\n",
        "- `random_state=100`\n",
        "\n",
        "**`18.3.3`** Calcula diferentes métricas para evaluar este modelo y analiza su rendimiendo.\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "- Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68459810",
      "metadata": {
        "id": "68459810"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1181a3c8",
      "metadata": {
        "id": "1181a3c8"
      },
      "source": [
        "### **`Ejercicio 18.4`**\n",
        "\n",
        "Ahora probamos la creación de otros modelo basados en **árboles de decisión**:  \n",
        "\n",
        "**`18.4.1`** Entrena un modelo tipo **Decision Tree Classifire** y calcula las métricas correspondientes para analizar su rendimiento en comparación con el modelo anterior:\n",
        "- `random_state=100`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "\n",
        "**`18.4.2`** Saca la curva de complejidad del modelo _Decision Tree_ (**Model Complexity Curve**) y crea un nuevo clasificador **con el valor óptimo de la profundidad del árbol** según esta gráfica. Después saca las métricas correspondiente y analiza el rendimiento del modelo en comparación de los anteriores.\n",
        "- `random_state=100`\n",
        "- rango de profundidades:  de `2` a `30` __inclusive__\n",
        "\n",
        "**`18.4.3`** Saca la gráfica de el *Learning Curve* para estos modelos, definiendo y aplicando una función que toma el valor del hiperparámetro como su entrada y dibuja la evolución del rendimiento del modelo para el conjunto de training y de test. Explica si este último modelo tiene preferencia o no, comparando con modelos anteriores.\n",
        "- `random_state=100`\n",
        "- (*Sugerencia*: No incluya más de 10 puntos en el eje horizontal y empieza la gráfica con un mínimo de _1000_ muestras para el modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc96a0e",
      "metadata": {
        "id": "2bc96a0e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5acde38f",
      "metadata": {
        "id": "5acde38f"
      },
      "source": [
        "### **`Ejercicio 18.5`**\n",
        "\n",
        "Ahora probamos la creación de otros modelo basados en **bosques aleatorios**:  \n",
        "\n",
        "**`18.5.1`** Entrena un modelo tipo **Random Forest Classifire** y calcula las métricas correspondientes para analizar su rendimiento en comparación con los modelos anteriores:\n",
        "- `random_state=100`\n",
        "\n",
        "**`18.5.2`** Consulta la profundidad de todos los árboles del bosque creado en el paso anterior y calcula la mediana de este parámetro.\n",
        "\n",
        "**`18.5.3`** Saca las curvas de complejidad del modelo _Random Forest_ (**Model Complexity Curve**) y crea un nuevo clasificador **con los valores óptimos** analizados dentro de los rangos indicados para cada hiperparámeto. Después crea un modelo con estos parámetros \"óptimos\" y saca las métricas correspondientes para analizar el rendimiento del modelo en comparación con los anteriores.\n",
        "- `random_state=100`\n",
        "- define un rango con funciones de _numpy_ para considerar estos números de árboles: `[200, 250, 300, 350, 400]`  \n",
        "- rango de profundidades:  de `20` a `40` __inclusive__ en pasos de 2 en 2.\n",
        "- considera estas opciones para _max_features_ : `[\"auto\", \"log2\", None]`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "- **OOB** (out-of-bag score)\n",
        "\n",
        "**`18.5.4`** Saca la gráfica del *Learning Curve* para estos modelos, definiendo y aplicando una función que toma el valor de los hiperparámetros analizados como su entrada y dibuja la evolución del rendimiento del modelo para el conjunto de training y de test. Explica si este último modelo tiene preferencia o no, comparando con modelos anteriores.\n",
        "- `random_state=100`\n",
        "- (*Sugerencia*: No incluya más de 10 puntos en el eje horizontal y empieza la gráfica con un mínimo de _1000_ muestras para el modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb23696",
      "metadata": {
        "id": "7cb23696"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ed7fa6f",
      "metadata": {
        "id": "3ed7fa6f"
      },
      "source": [
        "### **`Ejercicio 18.6`**\n",
        "\n",
        "Ahora probamos la creación de otros modelo basados en **Gradient Boosting**:  \n",
        "\n",
        "**`18.6.1`** Entrena un modelo tipo **XGBoost Classifire** y calcula las métricas correspondientes para analizar su rendimiento en comparación con los modelos anteriores:\n",
        "- `random_state=100`\n",
        "\n",
        "**`18.6.2`** Consulta el número y la profundidad máxima de los árboles del bosque creado en el paso anterior.\n",
        "\n",
        "**`18.6.3`** Saca las curvas de complejidad del modelo _XGBClassifier_ (**Model Complexity Curve**) y crea un nuevo clasificador **con los valores óptimos** analizados dentro de los rangos indicados para cada hiperparámeto. Después crea un modelo con estos parámetros \"óptimos\" y saca las métricas correspondientes para analizar el rendimiento del modelo en comparación con los anteriores.\n",
        "- `random_state=100`\n",
        "- define un rango con funciones de _numpy_ para considerar estos números de árboles: `[100, 200, 300, 400, 500]`  \n",
        "- rango de profundidades:  de `6` a `20` __inclusive__ en pasos de 2 en 2.\n",
        "- valores a considerar para el *`learning_rate`*: `[0.01, 0.1, 0.3, 0.5]`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "\n",
        "**`18.6.4`** Saca la gráfica del *Learning Curve* para estos modelos, definiendo y aplicando una función que toma el valor de los hiperparámetros analizados como su entrada y dibuja la evolución del rendimiento del modelo para el conjunto de training y de test. Explica si este último modelo tiene preferencia o no, comparando con modelos anteriores.\n",
        "- `random_state=100`\n",
        "- (*Sugerencia*: No incluya más de 10 puntos en el eje horizontal y empieza la gráfica con un mínimo de _1000_ muestras para el modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76362b0b",
      "metadata": {
        "id": "76362b0b"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5bb8ab",
      "metadata": {
        "id": "bf5bb8ab"
      },
      "source": [
        "### **`Ejercicio 18.7`**\n",
        "\n",
        "Ahora probamos la creación de otros modelo basados en **métodos Bayesianos**:  \n",
        "\n",
        "**`18.7.1`** Entrena un modelo para cada tipo de algoritmos Bayesianos y calcula las métricas correspondientes para analizar sus rendimientos en comparación con los modelos anteriores:\n",
        "- `GaussianNB`\n",
        "- `MultinomialNB`\n",
        "- `ComplementNB`\n",
        "- `BernoulliNB`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "\n",
        "**`18.7.2`** Saca la gráfica del *Learning Curve* para el modelo `GaussianNB` y explica si este modelo sufre de un posible \"_Overfitting_\" o \"_Underfitting_\" comparando con modelos anteriores.\n",
        "- `random_state=100`\n",
        "- (*Sugerencia*: No incluya más de 10 puntos en el eje horizontal y empieza la gráfica con un mínimo de _1000_ muestras para el modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66690c81",
      "metadata": {
        "id": "66690c81"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33eec61a",
      "metadata": {
        "id": "33eec61a"
      },
      "source": [
        "### **`Ejercicio 18.8`**\n",
        "\n",
        "Ahora probamos la creación de otros modelo basados en **K vecinos más cercanos**:  \n",
        "\n",
        "**`18.8.1`** Entrena un modelo tipo **K-Nearest Neighbors** con la configuración por defecto y otros dos modelos con `1` y `100` vecinos más cercanos. Calcula las métricas correspondientes para analizar sus rendimientos en comparación con el modelo anteriores:\n",
        "- `random_state=100`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "\n",
        "**`18.8.2`** Saca la gráfica del *Learning Curve* para estos modelos, definiendo y aplicando una función que toma el valor del hiperparámetro analizado como su entrada y dibuja la evolución del rendimiento del modelo para el conjunto de training y de test. Explica si este último modelo tiene preferencia o no, comparando con modelos anteriores.\n",
        "- (*Sugerencia*: No incluya más de 5 puntos en el eje horizontal y empieza la gráfica con un mínimo de _1000_ muestras para el modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8950a61",
      "metadata": {
        "id": "b8950a61"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0fc8786",
      "metadata": {
        "id": "a0fc8786"
      },
      "source": [
        "### **`Ejercicio 18.9`**\n",
        "\n",
        "Ahora probamos la creación de otros modelo basados en **Redes Neuronales**:  \n",
        "\n",
        "**`18.9.1`** Entrena un modelo tipo **MLPClassifier** y calcula las métricas correspondientes para analizar su rendimiento en comparación con los modelos anteriores:\n",
        "- `random_state=100`\n",
        "\n",
        "\n",
        "**`18.9.2`** Entrena otro modelo tipo _MLPClassifier_ indicando los siguientes hiperparámetros y calcula las métricas correspondientes para analizar su rendimiento en comparación con los modelos anteriores:\n",
        "- `random_state=100`\n",
        "- `hidden_layer_sizes=(100,200,100)`\n",
        "- Número máximo de iteraciones igual a `10000`\n",
        "- `alpha=1e-5`\n",
        "- `tol=1e-5`\n",
        "\n",
        "**`18.9.3`** Construye con la misma estructura del modelo definido en el paso anterior, una red neuronal profunda (**DNN**-Deep Neural Networks) usando la librería _keras_  realizando las preparaciones y tratamientos necesarias al respecto y considerando los siguientes parámetros. Después, calcula las métricas correspondientes para analizar su rendimiento en comparación con los modelos anteriores:\n",
        "- `semilla = 883`\n",
        "- `epochs = 50`\n",
        "- `batch_size=100`\n",
        "- `loss='binary_crossentropy`\n",
        "- `optimizer='Adam'`\n",
        "- `umbral = 0.5`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "\n",
        "**`18.9.4`** Crea otra red neuronal profunda usando _keras_ y considerando los siguientes parámetros. Después, calcula las métricas correspondientes para analizar su rendimiento en comparación con los modelos anteriores:\n",
        "- Definir las capas ocultas:\n",
        "   - Una capa densa con **50** neuronas y la misma función de activación que la red anterior\n",
        "   - Una capa densa con **100** neuronas y la misma función de activación que la red anterior\n",
        "   - Una capa densa con **200** neuronas y la misma función de activación que la red anterior\n",
        "   - Una capa densa con **1000** neuronas y la misma función de activación que la red anterior\n",
        "   - Una capa densa con **200** neuronas y la misma función de activación que la red anterior\n",
        "   - Una capa densa con **100** neuronas y la misma función de activación que la red anterior\n",
        "   - Una capa densa con **50** neuronas y la misma función de activación que la red anterior\n",
        "      \n",
        "- `semilla = 883`\n",
        "- `epochs = 40`\n",
        "- `batch_size=100`\n",
        "- `loss='binary_crossentropy`\n",
        "- `optimizer='Adam'`\n",
        "- `umbral = 0.5`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "\n",
        "**`18.9.5`** Saca la gráfica del *Learning Curve* para este último modelo y explica si tiene preferencia o no, comparando con modelos anteriores.\n",
        "- `semilla = 883`\n",
        "- `epochs = 40`\n",
        "- `batch_size=8000`\n",
        "- `loss='binary_crossentropy`\n",
        "- `optimizer='Adam'`\n",
        "- `umbral = 0.5`\n",
        "- Accuracy\n",
        "- F1-score `(average='weighted')`\n",
        "- Classification report `(zero_division=0)`\n",
        "- (*Sugerencia*: No incluya más de **5** puntos en el eje horizontal y empieza la gráfica con un mínimo de _1000_ muestras para el modelo)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}